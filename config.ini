[model]
enc_hidden_size = 512
enc_num_layers = 2
dec_hidden_size = 512
dec_num_layers = 2
enc_bidirection = True
dec_bidirection = False
attention_variant = LUONG

[luong]
luong_variant = general
luong_type = local 
d = 5

[training]
batch_size = 25
max_length = 30
test_size = 0.3
epochs = 10
input_lang = eng
output_lang = fra